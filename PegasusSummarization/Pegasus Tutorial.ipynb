{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0. Install dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in links: https://download.pytorch.org/whl/lts/1.8/torch_lts.html\n",
      "Requirement already satisfied: torch==1.8.2+cu111 in c:\\users\\james\\anaconda3\\lib\\site-packages (1.8.2+cu111)\n",
      "Collecting torchvision==0.9.2+cu111\n",
      "  Using cached https://download.pytorch.org/whl/lts/1.8/cu111/torchvision-0.9.2%2Bcu111-cp38-cp38-win_amd64.whl (1.9 MB)\n",
      "Collecting torchaudio===0.8.2\n",
      "  Using cached https://download.pytorch.org/whl/lts/1.8/torchaudio-0.8.2-cp38-none-win_amd64.whl (109 kB)\n",
      "Requirement already satisfied: numpy in c:\\users\\james\\anaconda3\\lib\\site-packages (from torch==1.8.2+cu111) (1.19.5)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\james\\anaconda3\\lib\\site-packages (from torch==1.8.2+cu111) (3.7.4.2)\n",
      "Requirement already satisfied: pillow>=4.1.1 in c:\\users\\james\\anaconda3\\lib\\site-packages (from torchvision==0.9.2+cu111) (7.2.0)\n",
      "Installing collected packages: torchvision, torchaudio\n",
      "  Attempting uninstall: torchvision\n",
      "    Found existing installation: torchvision 0.9.1+cu111\n",
      "    Uninstalling torchvision-0.9.1+cu111:\n",
      "      Successfully uninstalled torchvision-0.9.1+cu111\n",
      "  Attempting uninstall: torchaudio\n",
      "    Found existing installation: torchaudio 0.8.1\n",
      "    Uninstalling torchaudio-0.8.1:\n",
      "      Successfully uninstalled torchaudio-0.8.1\n",
      "Successfully installed torchaudio-0.8.2 torchvision-0.9.2+cu111\n"
     ]
    }
   ],
   "source": [
    "# Install PyTorch\n",
    "!pip install torch==1.8.2+cu111 torchvision==0.9.2+cu111 torchaudio===0.8.2 -f https://download.pytorch.org/whl/lts/1.8/torch_lts.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in c:\\users\\james\\anaconda3\\lib\\site-packages (4.6.1)\n",
      "Requirement already satisfied: huggingface-hub==0.0.8 in c:\\users\\james\\anaconda3\\lib\\site-packages (from transformers) (0.0.8)\n",
      "Requirement already satisfied: packaging in c:\\users\\james\\anaconda3\\lib\\site-packages (from transformers) (20.4)\n",
      "Requirement already satisfied: tokenizers<0.11,>=0.10.1 in c:\\users\\james\\anaconda3\\lib\\site-packages (from transformers) (0.10.3)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\james\\anaconda3\\lib\\site-packages (from transformers) (1.19.5)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\james\\anaconda3\\lib\\site-packages (from transformers) (4.47.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\james\\anaconda3\\lib\\site-packages (from transformers) (3.0.12)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\james\\anaconda3\\lib\\site-packages (from transformers) (2020.6.8)\n",
      "Requirement already satisfied: sacremoses in c:\\users\\james\\anaconda3\\lib\\site-packages (from transformers) (0.0.45)\n",
      "Requirement already satisfied: requests in c:\\users\\james\\anaconda3\\lib\\site-packages (from transformers) (2.24.0)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in c:\\users\\james\\anaconda3\\lib\\site-packages (from packaging->transformers) (2.4.7)\n",
      "Requirement already satisfied: six in c:\\users\\james\\anaconda3\\lib\\site-packages (from packaging->transformers) (1.15.0)\n",
      "Requirement already satisfied: joblib in c:\\users\\james\\anaconda3\\lib\\site-packages (from sacremoses->transformers) (0.16.0)\n",
      "Requirement already satisfied: click in c:\\users\\james\\anaconda3\\lib\\site-packages (from sacremoses->transformers) (7.1.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\james\\anaconda3\\lib\\site-packages (from requests->transformers) (2021.5.30)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in c:\\users\\james\\anaconda3\\lib\\site-packages (from requests->transformers) (1.25.11)\n",
      "Requirement already satisfied: idna<3,>=2.5 in c:\\users\\james\\anaconda3\\lib\\site-packages (from requests->transformers) (2.10)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in c:\\users\\james\\anaconda3\\lib\\site-packages (from requests->transformers) (3.0.4)\n"
     ]
    }
   ],
   "source": [
    "# Install transformers\n",
    "!pip install transformers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Import and Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\james\\anaconda3\\lib\\site-packages\\numpy\\_distributor_init.py:30: UserWarning: loaded more than 1 DLL from .libs:\n",
      "C:\\Users\\james\\anaconda3\\lib\\site-packages\\numpy\\.libs\\libopenblas.PYQHXLVVQ7VESDPUVUADXEVJOBGHJPAY.gfortran-win_amd64.dll\n",
      "C:\\Users\\james\\anaconda3\\lib\\site-packages\\numpy\\.libs\\libopenblas.WCDJNK7YVMPZQ2ME2ZZHJJRJ3JIKNDB7.gfortran-win_amd64.dll\n",
      "  warnings.warn(\"loaded more than 1 DLL from .libs:\"\n"
     ]
    }
   ],
   "source": [
    "# Importing dependencies from transformers\n",
    "from transformers import PegasusForConditionalGeneration, PegasusTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6eedcdf50259471c8accc0cc97eabd15",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=1912529.0, style=ProgressStyle(descript…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fc2b79d9bbcb4bf09add9ec9cbdd627f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=65.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "66ad96249390416091cb2ed51ca5bc93",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=87.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d0e615a89db740fb9fa0defeeabd7621",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=3520083.0, style=ProgressStyle(descript…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Load tokenizer \n",
    "tokenizer = PegasusTokenizer.from_pretrained(\"google/pegasus-xsum\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model \n",
    "model = PegasusForConditionalGeneration.from_pretrained(\"google/pegasus-xsum\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Perform Abstractive Summarization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"\"\"\n",
    "Python is an interpreted high-level general-purpose programming language. Its design philosophy emphasizes code readability with its use of significant indentation. Its language constructs as well as its object-oriented approach aim to help programmers write clear, logical code for small and large-scale projects.[30]\n",
    "\n",
    "Python is dynamically-typed and garbage-collected. It supports multiple programming paradigms, including structured (particularly, procedural), object-oriented and functional programming. It is often described as a \"batteries included\" language due to its comprehensive standard library.[31]\n",
    "\n",
    "Guido van Rossum began working on Python in the late 1980s, as a successor to the ABC programming language, and first released it in 1991 as Python 0.9.0.[32] Python 2.0 was released in 2000 and introduced new features, such as list comprehensions and a garbage collection system using reference counting. Python 3.0 was released in 2008 and was a major revision of the language that is not completely backward-compatible. Python 2 was discontinued with version 2.7.18 in 2020.[33]\n",
    "\n",
    "Python consistently ranks as one of the most popular programming languages.[34][35][36][37]\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create tokens - number representation of our text\n",
    "tokens = tokenizer(text, truncation=True, padding=\"longest\", return_tensors=\"pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[11994,   117,   142, 15186,   281,   121,  3393,   956,   121, 14621,\n",
       "          3661,  1261,   107,  3096,   354,  4679, 18390,   929, 39331,   122,\n",
       "           203,   207,   113,  1225, 58339,   107,  3096,  1261, 38059,   130,\n",
       "           210,   130,   203,  2951,   121,  8321,  1014,  2560,   112,   225,\n",
       "         19003,  1094,   786,   108,  8789,   929,   118,   360,   111,   423,\n",
       "           121,  5129,   844,   107,  4101,  4311,  1100, 11994,   117, 22717,\n",
       "           121,  7155,   252,   111,  9041,   121, 83800,   107,   168,  3000,\n",
       "          1079,  3661, 50877,   108,   330,  7314,   143, 24899,   108, 22000,\n",
       "           312,  2951,   121,  8321,   111,  3819,  3661,   107,   168,   117,\n",
       "           432,  2540,   130,   114,   198, 18077,   144, 32300,   953,   194,\n",
       "          1261,   640,   112,   203,  2250,   971,  2400,   107,  4101, 10822,\n",
       "          1100, 58937,  4406,  7366,  3707,  1219,   375,   124, 11994,   115,\n",
       "           109,  1095,  5940,   116,   108,   130,   114, 15749,   112,   109,\n",
       "          8172,  3661,  1261,   108,   111,   211,  1291,   126,   115, 12086,\n",
       "           130, 11994, 21544,   107, 24613,  4101,  6695,  1100, 11994,  4586,\n",
       "           140,  1291,   115,  3555,   111,  2454,   177,   556,   108,   253,\n",
       "           130,   467, 17673,   116,   111,   114,  9041,   949,   327,   303,\n",
       "          2334,  8742,   107, 11994,  9179,   140,  1291,   115,  3390,   111,\n",
       "           140,   114,   698, 11827,   113,   109,  1261,   120,   117,   146,\n",
       "          1127, 17868,   121, 37804,   107, 11994,   280,   140, 17921,   122,\n",
       "           824, 21672,   107,  4876,   115, 12573,  4101,  9773,  1100, 11994,\n",
       "          4409,  7329,   130,   156,   113,   109,   205,   785,  3661,  4482,\n",
       "           107,  4101, 12365, 32887,  7393, 32887,  9368, 32887, 13185,  1100,\n",
       "             1]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Input tokens\n",
    "tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summarize \n",
    "summary = model.generate(**tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([    0, 11994,   117,   114,  3661,  1261,  1184,   141, 58937,  4406,\n",
       "         7366,  3707,   107,     1])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Output summary tokens\n",
    "summary[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Python is a programming language developed by Guido van Rossum.'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Decode summary\n",
    "tokenizer.decode(summary[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['\"Crossing at a ford\" means, for example, crossing the sea at a strait, \\n',\n",
       " 'or crossing over a hundred miles of broad sea at a crossing place.\\n',\n",
       " 'I believe this \"crossing at a ford\" occurs often in a man\\'s lifetime.\\n',\n",
       " 'It means setting sail even though you friends stay in harbour, \\n',\n",
       " 'knowing the route, knowing the soundness of your ship and the favour \\n',\n",
       " 'of the day. When all the conditions are meet, and there is perhaps a \\n',\n",
       " 'favourable wind, or a tailwind, then set sail. If the wind changes within a few miles of your destination, you must row across the remaining distance without sail. If you attain this spirit, it applies to everyday life. You must always think of crossing at a ford.\\n',\n",
       " '\\n',\n",
       " '- Miyamoto Musashi\\n',\n",
       " '\\n',\n",
       " 'A Book of Five Rings']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Reading from a file\n",
    "with open('Musashi_Ford.txt', 'r') as f:\n",
    "    text2 = f.readlines()\n",
    "text2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\"Crossing at a ford\" means, for example, crossing the sea at a strait, \\nor crossing over a hundred miles of broad sea at a crossing place.\\nI believe this \"crossing at a ford\" occurs often in a man\\'s lifetime.\\nIt means setting sail even though you friends stay in harbour, \\nknowing the route, knowing the soundness of your ship and the favour \\nof the day. When all the conditions are meet, and there is perhaps a \\nfavourable wind, or a tailwind, then set sail. If the wind changes within a few miles of your destination, you must row across the remaining distance without sail. If you attain this spirit, it applies to everyday life. You must always think of crossing at a ford.\\n\\n- Miyamoto Musashi\\n\\nA Book of Five Rings'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text2 = ''.join(str(line) for line in text2)\n",
    "text2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens2 = tokenizer(text2, truncation=True, padding=\"longest\", return_tensors=\"pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[  198, 76783,   134,   114,   118,   252,   194,   495,   108,   118,\n",
       "           587,   108,  7452,   109,  1917,   134,   114, 50788,   108,   132,\n",
       "          7452,   204,   114,  4062,  1567,   113,  3426,  1917,   134,   114,\n",
       "          7452,   295,   107,   125,   697,   136,   198, 67340,   134,   114,\n",
       "           118,   252,   194,  4403,   432,   115,   114,   729,   131,   116,\n",
       "          3913,   107,   168,   495,  1374, 10983,   254,   577,   119,   594,\n",
       "           753,   115, 14737,   108,  2753,   109,  2610,   108,  2753,   109,\n",
       "          1056,  1759,   113,   128,  2530,   111,   109,  9624,   113,   109,\n",
       "           242,   107,   434,   149,   109,  1047,   127,   670,   108,   111,\n",
       "           186,   117,  1850,   114, 24314,  2316,   108,   132,   114, 93093,\n",
       "           108,   237,   323, 10983,   107,   240,   109,  2316,   852,   373,\n",
       "           114,   324,  1567,   113,   128,  2705,   108,   119,   355,  3843,\n",
       "           482,   109,  2756,  2028,   347, 10983,   107,   240,   119, 11439,\n",
       "           136,  2748,   108,   126,  4943,   112,  2762,   271,   107,   226,\n",
       "           355,   329,   311,   113,  7452,   134,   114,   118,   252,   107,\n",
       "           233, 38956, 28222, 20403, 30253,   202,  2459,   113,  6418, 17557,\n",
       "             1]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summarize \n",
    "summary2 = model.generate(**tokens2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The word \"Crossing at a ford\" comes from the Japanese word for \"to set sail\".'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Decode summary\n",
    "tokenizer.decode(summary2[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
